---
title: "Launch pipelines"
description: "An introduction to launching nf-core/rnaseq in the community/showcase workspace"
date: "8 Jul 2024"
tags: [platform, launch, pipelines, launchpad, showcase tutorial]
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

:::info
This tutorial provides an introduction to launching pipelines in Seqera Platform.

Before you can run pipelines on your own compute infrastructure, do the following:
1. [Set up an organization and workspace](../workspace-setup.mdx).
1. Create a workspace [compute environment](../../compute-envs/overview.mdx) for your cloud or HPC compute infrastructure.
1. [Add a pipeline](./add-pipelines.mdx) to your workspace.
1. [Add your pipeline input data](./add-data.mdx).
:::

The Launchpad in every Platform workspace allows users to easily create and share Nextflow pipelines that can be executed on any supported infrastructure, including all public clouds and most HPC schedulers. A Launchpad pipeline consists of a pre-configured workflow repository, [compute environment](../../compute-envs/overview.mdx), and launch parameters.

## Launch the nf-core/rnaseq pipeline

:::note
This guide is based on version 3.15.1 of the nf-core/rnaseq pipeline. Launch form parameters and tools may differ in other versions. 
:::

Navigate to the Launchpad and select **Launch** next to your pipeline to open the launch form.

The launch form consists of **General config**, **Run parameters**, and **Advanced options** sections to specify your run parameters before execution, and an execution summary. Use section headings or select the **Previous** and **Next** buttons at the bottom of the page to navigate between sections. 

<details>
  <summary>Nextflow parameter schema</summary>

  The launch form lets you configure the pipeline execution. The pipeline parameters in this form are rendered from a [pipeline schema](../../pipeline-schema/overview.mdx) file in the root of the pipeline Git repository. `nextflow_schema.json` is a simple JSON-based schema describing pipeline parameters for pipeline developers to easily adapt their in-house Nextflow pipelines to be executed in Platform.

  :::tip
  See [Best Practices for Deploying Pipelines with the Seqera Platform](https://seqera.io/blog/best-practices-for-deploying-pipelines-with-seqera-platform/) to learn how to build the parameter schema for any Nextflow pipeline automatically with tooling maintained by the nf-core community. 
  :::

</details>

### General config 

Most Showcase pipeline parameters are prefilled. Specify the following fields to identify your run amongst other workspace runs:

- **Workflow run name**: A unique identifier for the run, pre-filled with a random name. This can be customized.
- **Labels**: Assign new or existing labels to the run. For example, a project ID or genome version.

### Run parameters 

There are three ways to enter **Run parameters** prior to launch:

- The **Input form view** displays form fields to enter text, select attributes from dropdowns, and browse input and output locations with [Data Explorer](../data/data-explorer.mdx).
- The **Config view** displays a raw schema that you can edit directly. Select JSON or YAML format from the **View as** dropdown.
- **Upload params file** allows you to upload a JSON or YAML file with run parameters.

#### input

Most nf-core pipelines use the `input` parameter in a standardized way to specify an input samplesheet that contains paths to input files (such as FASTQ files) and any additional metadata needed to run the pipeline. Use **Browse** to select either a file path in cloud storage via **Data Explorer**, or a pre-loaded **Dataset**: 

- In the **Data Explorer** tab, select the `nf-tower-data` bucket, then search for and select the `rnaseq_sample_data.csv` file.
- In the **Datasets** tab, search for and select `rnaseq_sample_data`.

![Input parameters](../_images/cs-launch-input.gif)

:::tip
See [Add data](./add-data.mdx) to learn how to add datasets and Data Explorer cloud buckets to your own workspaces.
:::

#### output

Most nf-core pipelines use the `outdir` parameter in a standardized way to specify where the final results created by the pipeline are published. `outdir` must be unique for each pipeline run. Otherwise, your results will be overwritten. 

For this tutorial test run, keep the default `outdir` value (`./results`).

:::tip 
For the `outdir` parameter in pipeline runs in your own workspace, select **Browse** to specify a cloud storage directory using Data Explorer, or enter a cloud storage directory path to publish pipeline results to manually.
:::

#### Pipeline-specific parameters

Modify other parameters to customize the pipeline execution through the parameters form. For example, under **Read trimming options**, change the `trimmer` to select `fastp` in the dropdown menu instead of `trimgalore`.

![Read trimming options](./assets/trimmer-settings.png)

Select **Launch** to start the run and be directed to the **Runs** tab with your run in a **submitted** status at the top of the list.